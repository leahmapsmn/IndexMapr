{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ IndexMapr\n",
    "### From field to folderâ€”automatically mapped.\n",
    "#### IndexMapr is a streamlined GIS tool that automatically organizes site photos by street and house numberâ€”creating a spatially-aware folder structure from any table. Designed for field data workflows, this tool reads your survey data (CSV, Excel, or feature class), builds a clean hierarchy of folders by location, and downloads associated images into the right place.\n",
    "\n",
    "#### Whether youâ€™re tracking installations, inspections, or field notes, Image Indexer turns messy tables into map-friendly media librariesâ€”with zero stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Enter path to your input table (CSV, Excel, or feature class):  C:\\Users\\leahe\\Desktop\\mgis\\_SPRING25\\GEOCOMP_GradPrj\\GEOCOMP_GradPrj.gdb\\DoFormsData\n",
      "ğŸ“‚ Enter output folder path:  C:\\Users\\leahe\\Desktop\\mgis\\_SPRING25\\GEOCOMP_GradPrj\\_OUTPUT_TESTING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§­ Loading feature class from GDB: DoFormsData\n",
      "ğŸ”— Detected URL columns: ['meter_before_installation', 'meter_after_installation', 'sump_pump', 'sump_pump_discharge', 'customer_signature', 'minode']\n",
      "\n",
      "ğŸš€ Processing records and downloading images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4c58eae20c4b68abb4fdc585426f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All done! Your images are organized by group > street > house.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse\n",
    "import pathlib\n",
    "import arcpy\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\"\"\"\n",
    "ğŸ—ºï¸ IndexMapr\n",
    "------------------------------------------------\n",
    "IndexMapr is a geospatial utility designed for organizing field photos using structured data. \n",
    "Given a CSV, Excel file, or a table from an ArcGIS feature class, it builds a folder hierarchy by street\n",
    "and house number, detects valid image URLs, and downloads those images into the appropriate subfolders.\n",
    "\n",
    "Why it matters: In fieldwork and asset management, properly sorted images save time, reduce error,\n",
    "and enhance reporting clarity. This tool bridges the gap between field data and usable outputs\n",
    "in mapping workflows.\n",
    "\n",
    "Features:\n",
    "- Accepts multiple input formats (CSV, Excel, feature class)\n",
    "- Detects image URL columns automatically\n",
    "- Organizes outputs as: [Group] > [Street] > [House]\n",
    "- Simple progress tracking with `tqdm`\n",
    "\n",
    "â— Note: Direct image hosting is preferred. Avoid platforms like Google Drive that serve HTML pages instead of raw image bytes.\n",
    "\n",
    "Ideal for: planners, surveyors, field crews, GIS analysts, and anyone who has wrestled with folders full of unlabeled photos.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "ğŸ§  What This Tool Does â€” Plain English Summary\n",
    "------------------------------------------------\n",
    "This notebook lets you take a spreadsheet (or ArcGIS table) full of site photos and related info, and turn it\n",
    "into an organized folder system. You pick where the output should go. It reads your table, figures out\n",
    "which columns are images, and automatically downloads those photos into folders sorted by street and house.\n",
    "\n",
    "For example, all houses on \"Emmer Place\" will go into their own folder inside a parent one called \"E streets.\"\n",
    "If the street starts with numbers like \"128th\", it groups those under \"120s.\"\n",
    "\n",
    "This saves time for teams that need quick access to field documentation â€” like utility inspections or tree inventory photos.\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ¯ USER INPUTS ----------------------------------------------------\n",
    "input_path_raw = input(\"ğŸ“ Enter path to your input table (CSV, Excel, or feature class): \").strip()\n",
    "input_path = input_path_raw.replace('\\\\', '/')  # Normalize for ArcGIS compatibility\n",
    "output_dir = pathlib.Path(input(\"ğŸ“‚ Enter output folder path: \").strip())\n",
    "\n",
    "# ğŸ“¦ LOAD TABLE ------------------------------------------------------\n",
    "\"\"\"\n",
    "ğŸ“„ Data Input Flexibility\n",
    "------------------------------------------------\n",
    "This tool supports multiple input types: CSV files, Excel workbooks (.xlsx or .xls),\n",
    "and tables from ArcGIS geodatabases (feature classes). This flexibility makes it adaptable\n",
    "for both GIS and non-GIS workflows.\n",
    "\"\"\"\n",
    "\n",
    "if input_path.lower().endswith('.csv'):\n",
    "    df = pd.read_csv(input_path)\n",
    "elif input_path.lower().endswith(('.xlsx', '.xls')):\n",
    "    df = pd.read_excel(input_path)\n",
    "elif '.gdb/' in input_path or '.gdb\\\\' in input_path:\n",
    "    if '.gdb/' in input_path:\n",
    "        ws_part, table_name = input_path.split('.gdb/', 1)\n",
    "        workspace = ws_part + '.gdb'\n",
    "    else:\n",
    "        ws_part, table_name = input_path.split('.gdb\\\\', 1)\n",
    "        workspace = ws_part + '.gdb'\n",
    "    arcpy.env.workspace = workspace\n",
    "    print(f\"ğŸ§­ Loading feature class from GDB: {table_name}\")\n",
    "    arr = arcpy.da.TableToNumPyArray(table_name, '*')\n",
    "    df = pd.DataFrame({field: arr[field].tolist() for field in arr.dtype.names})\n",
    "elif arcpy.Exists(input_path):\n",
    "    print(f\"ğŸ§­ Loading feature class from path: {input_path}\")\n",
    "    arr = arcpy.da.TableToNumPyArray(input_path, '*')\n",
    "    df = pd.DataFrame({field: arr[field].tolist() for field in arr.dtype.names})\n",
    "else:\n",
    "    raise ValueError(\"âŒ Couldn't load input table. Double-check your path.\")\n",
    "\n",
    "# ğŸ§¹ CLEANUP & CHECKS ------------------------------------------------\n",
    "col_map = {col.lower(): col for col in df.columns}\n",
    "if 'street' not in col_map or 'house' not in col_map:\n",
    "    raise KeyError(\"âŒ Required columns 'Street' and 'House' are missing.\")\n",
    "df.rename(columns={col_map['street']: 'Street', col_map['house']: 'House'}, inplace=True)\n",
    "df['Street'] = df['Street'].astype(str)\n",
    "\n",
    "url_cols = [col for col in df.columns if df[col].astype(str).str.lower().str.startswith(('http://', 'https://')).any()]\n",
    "print(\"ğŸ”— Detected URL columns:\", url_cols)\n",
    "\n",
    "# ğŸ—ºï¸ GROUP LOGIC ------------------------------------------------------\n",
    "def group_key(name):\n",
    "    m = re.match(r\"(\\d+)\", name)\n",
    "    if m:\n",
    "        return f\"{int(m.group(1))//10*10}s\"\n",
    "    return f\"{name[0].upper()} streets\"\n",
    "\n",
    "# ğŸ“‚ FOLDER SETUP -----------------------------------------------------\n",
    "\"\"\"\n",
    "ğŸ“ Folder Structure Logic\n",
    "------------------------------------------------\n",
    "This tool creates a two-level folder grouping before reaching the house number:\n",
    "1. **Group Folder**: Based on the first letter (e.g., \"E streets\") or numeric tens (e.g., \"120s\") from the street name.\n",
    "   - Streets like *Emmer Court* and *Edinborough Way* go under **E streets**.\n",
    "   - Streets like *128th St W* go under **120s**.\n",
    "2. **Street Folder**: One folder per unique street name.\n",
    "3. **House Folder**: Each house number gets its own folder within the street folder.\n",
    "\n",
    "Example:\n",
    "  _OUTPUT_FOLDER/120s/128th St W/7018/...\n",
    "  _OUTPUT_FOLDER/E streets/Edinborough Way/12681/...\n",
    "\"\"\"\n",
    "\n",
    "for g in set(df['Street'].apply(group_key)):\n",
    "    (output_dir / g).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ğŸ“¸ DOWNLOAD PHOTOS --------------------------------------------------\n",
    "\"\"\"\n",
    "ğŸ“¸ Image Download Logic\n",
    "------------------------------------------------\n",
    "For each row, the tool checks each URL column for a valid link (starts with http/https).\n",
    "Each image is saved into its associated house folder using the column name as the filename.\n",
    "If a URL points to an image (like `.jpg` or `.png`), the extension is preserved. If no extension\n",
    "is found, `.jpg` is assumed. This helps ensure that the filenames stay traceable to the data\n",
    "column they came fromâ€”useful for analysis, reporting, or auditing.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸš€ Processing records and downloading images...\")\n",
    "for row in tqdm(df.itertuples(index=False), total=len(df), desc='Processing'):\n",
    "    g = group_key(row.Street)\n",
    "    street_dir = output_dir / g / row.Street\n",
    "    street_dir.mkdir(parents=True, exist_ok=True)\n",
    "    house_dir = street_dir / str(row.House)\n",
    "    house_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for col in url_cols:\n",
    "        url = getattr(row, col)\n",
    "        if isinstance(url, str) and url.lower().startswith(('http://', 'https://')):\n",
    "            parsed = urllib.parse.urlparse(url)\n",
    "            ext = pathlib.Path(parsed.path).suffix or '.jpg'\n",
    "            filename = f\"{col}{ext}\"\n",
    "            target = house_dir / filename\n",
    "            try:\n",
    "                r = requests.get(url, timeout=15)\n",
    "                r.raise_for_status()\n",
    "                with open(target, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Failed to download from {url}: {e}\")\n",
    "\n",
    "print(\"\\nâœ… All done! Your images are organized by group > street > house.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
